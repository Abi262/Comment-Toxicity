# Deep-Comment-Toxicity
Deep Comment Toxicity Model helps detect different elements of toxicity within a sentence like toxic, severe_toxic, obscene, threat, insult, identity_hate i.e., if a comment is classified as containing some or all of the above gradients of toxicity it will return 1(True) for those particular gradients else it will return 0(False).
# Dataset
jigsaw-toxic-comment-classification.
<br>
This dataset contains 159574 comments with multiple binary outputs (comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate).
# Requirements
Pandas: 1.3.5
<br>
Numpy: 1.21.6
<br>
Tensorflow: 2.9.2
<br>
Gradio: 3.16.1
# Output
![cmt_gradio](https://user-images.githubusercontent.com/114276347/215877203-cacc7440-c5ec-4b9a-b8ef-432f1d90ff8c.png)

